model(
  (conv1): GCNConv(200, 100)
  (pool1): SAGPooling(GraphConv, 100, ratio=0.5, multiplier=1)
  (conv2): GCNConv(100, 100)
  (pool2): SAGPooling(GraphConv, 100, ratio=0.5, multiplier=1)
  (conv3): GCNConv(100, 100)
  (pool3): SAGPooling(GraphConv, 100, ratio=0.5, multiplier=1)
  (lstm): LSTM(1, 1, num_layers=2, batch_first=True, bidirectional=True)
  (mlp): Sequential(
    (0): Linear(in_features=200, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=50, bias=True)
    (3): ReLU()
    (4): Linear(in_features=50, out_features=12, bias=True)
  )
)
cuda
Epoch 000 train_loss: 2.2863 train_acc: 0.1818
Epoch 001 train_loss: 1.9091 train_acc: 0.1818
(110, 250)
Epoch 002 train_loss: 1.6528 train_acc: 0.2727
Epoch 003 train_loss: 1.3839 train_acc: 0.4455
(110, 250)
Epoch 004 train_loss: 1.1651 train_acc: 0.4091
Epoch 005 train_loss: 0.9274 train_acc: 0.4455
Epoch 006 train_loss: 1.0118 train_acc: 0.4545
Epoch 007 train_loss: 0.9674 train_acc: 0.5000
(110, 250)
Epoch 008 train_loss: 0.6081 train_acc: 0.5182
(110, 250)
Epoch 009 train_loss: 0.8260 train_acc: 0.5455
Epoch 010 train_loss: 0.6121 train_acc: 0.4636
Epoch 011 train_loss: 0.8226 train_acc: 0.5364
(110, 250)
Epoch 012 train_loss: 0.9415 train_acc: 0.6545
(110, 250)
Epoch 013 train_loss: 1.1781 train_acc: 0.5636
Epoch 014 train_loss: 0.4751 train_acc: 0.5818
Epoch 015 train_loss: 0.8292 train_acc: 0.5455
Epoch 016 train_loss: 0.6690 train_acc: 0.6545
Epoch 017 train_loss: 0.6379 train_acc: 0.5727
Epoch 018 train_loss: 0.6692 train_acc: 0.6727
Epoch 019 train_loss: 0.9126 train_acc: 0.8273
Epoch 020 train_loss: 0.4482 train_acc: 0.7727
Epoch 021 train_loss: 0.6962 train_acc: 0.8273
Epoch 022 train_loss: 0.4789 train_acc: 0.8273
Epoch 023 train_loss: 0.3484 train_acc: 0.8091
Epoch 024 train_loss: 0.2690 train_acc: 0.9091
Epoch 025 train_loss: 0.2571 train_acc: 0.8091
Epoch 026 train_loss: 0.2536 train_acc: 0.8545
Epoch 027 train_loss: 0.2611 train_acc: 0.9000
Epoch 028 train_loss: 0.1003 train_acc: 0.8818
Epoch 029 train_loss: 0.2449 train_acc: 0.8727
Epoch 030 train_loss: 0.0553 train_acc: 0.8636
Epoch 031 train_loss: 0.1446 train_acc: 0.8636
Epoch 032 train_loss: 0.0896 train_acc: 0.9545
Epoch 033 train_loss: 0.1341 train_acc: 0.9182
Epoch 034 train_loss: 0.2874 train_acc: 0.9182
Epoch 035 train_loss: 0.4129 train_acc: 0.8000
Epoch 036 train_loss: 0.3558 train_acc: 0.8000
Epoch 037 train_loss: 0.2970 train_acc: 0.9000
Epoch 038 train_loss: 0.1665 train_acc: 0.8091
Epoch 039 train_loss: 0.1039 train_acc: 0.9182
Epoch 040 train_loss: 0.2367 train_acc: 0.8273
Epoch 041 train_loss: 0.0533 train_acc: 0.9545
Epoch 042 train_loss: 0.0450 train_acc: 0.9182
Epoch 043 train_loss: 0.1919 train_acc: 0.9364
Epoch 044 train_loss: 0.0725 train_acc: 0.9182
(110, 250)
Epoch 045 train_loss: 0.0374 train_acc: 0.8818
(110, 250)
Epoch 046 train_loss: 0.0427 train_acc: 0.9273
Epoch 047 train_loss: 0.1085 train_acc: 0.8909
Epoch 048 train_loss: 0.0111 train_acc: 0.8909
Epoch 049 train_loss: 0.0545 train_acc: 0.9455
Epoch 050 train_loss: 0.0734 train_acc: 0.9273
Epoch 051 train_loss: 0.0327 train_acc: 0.9182
Epoch 052 train_loss: 0.0180 train_acc: 0.9182
Epoch 053 train_loss: 0.1896 train_acc: 0.9273
Epoch 054 train_loss: 0.0119 train_acc: 0.8909
Epoch 055 train_loss: 0.0809 train_acc: 0.9182
Epoch 056 train_loss: 0.0102 train_acc: 0.9273
Epoch 057 train_loss: 0.0436 train_acc: 0.9182
Epoch 058 train_loss: 0.0117 train_acc: 0.9455
Epoch 059 train_loss: 0.0838 train_acc: 0.9364
Epoch 060 train_loss: 0.0074 train_acc: 0.9182
Epoch 061 train_loss: 0.0530 train_acc: 0.9273
Epoch 062 train_loss: 0.0366 train_acc: 0.8909
Epoch 063 train_loss: 0.0550 train_acc: 0.9273
Epoch 064 train_loss: 0.1375 train_acc: 0.9273
Epoch 065 train_loss: 0.0591 train_acc: 0.9273
Epoch 066 train_loss: 0.0070 train_acc: 0.9455
Epoch 067 train_loss: 0.0155 train_acc: 0.9455
Epoch 068 train_loss: 0.0046 train_acc: 0.9273
Epoch 069 train_loss: 0.0054 train_acc: 0.9364
Epoch 070 train_loss: 0.0158 train_acc: 0.9182
Epoch 071 train_loss: 0.0070 train_acc: 0.9545
Epoch 072 train_loss: 0.0503 train_acc: 0.9091
Epoch 073 train_loss: 0.0043 train_acc: 0.9364
Epoch 074 train_loss: 0.0030 train_acc: 0.9273
Epoch 075 train_loss: 0.0038 train_acc: 0.9364
Epoch 076 train_loss: 0.0205 train_acc: 0.9000
Epoch 077 train_loss: 0.0049 train_acc: 0.8909
Epoch 078 train_loss: 0.0148 train_acc: 0.9273
Epoch 079 train_loss: 0.0077 train_acc: 0.9273
Epoch 080 train_loss: 0.0105 train_acc: 0.9636
Epoch 081 train_loss: 0.0285 train_acc: 0.8909
Epoch 082 train_loss: 0.0405 train_acc: 0.8909
Epoch 083 train_loss: 0.0030 train_acc: 0.9273
Epoch 084 train_loss: 0.0087 train_acc: 0.9000
Epoch 085 train_loss: 0.9652 train_acc: 0.7727
Epoch 086 train_loss: 0.2200 train_acc: 0.7636
Epoch 087 train_loss: 0.1839 train_acc: 0.8182
Epoch 088 train_loss: 0.0837 train_acc: 0.8727
Epoch 089 train_loss: 0.0695 train_acc: 0.8727
Epoch 090 train_loss: 0.0117 train_acc: 0.9182
Epoch 091 train_loss: 0.0262 train_acc: 0.9182
Epoch 092 train_loss: 0.0392 train_acc: 0.9364
Epoch 093 train_loss: 0.0211 train_acc: 0.9545
Epoch 094 train_loss: 0.0297 train_acc: 0.9636
Epoch 095 train_loss: 0.0097 train_acc: 0.9364
Epoch 096 train_loss: 0.0471 train_acc: 0.9182
Epoch 097 train_loss: 0.0662 train_acc: 0.9455
Epoch 098 train_loss: 0.0351 train_acc: 0.9364
Epoch 099 train_loss: 0.0171 train_acc: 0.9182
